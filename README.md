# Retail Sales Data Warehouse

A portfolio project that demonstrates how to build a **mini data warehouse** for retail sales using **SQL, Python (Pandas), and PostgreSQL**.  
The project includes a simple **ETL pipeline**, a normalized schema, and analytical queries to uncover business insights.

## ğŸ—„ï¸ Data Model

The dataset includes columns: `Transaction ID`, `Date`, `Customer ID`, `Gender`, `Age`, `Product Category`, `Quantity`, `Price per Unit`, `Total Amount`.  

It was normalized into three tables:

- **customers**
  - `customer_id` (PK)  
  - `gender`  
  - `age`  

- **products**
  - `product_id` (PK, surrogate)  
  - `category`  
  - `price_per_unit`  

- **sales**
  - `transaction_id` (PK)  
  - `date`  
  - `customer_id` (FK â†’ customers)  
  - `product_id` (FK â†’ products)  
  - `quantity`  
  - `total_amount`

 ## âš™ï¸ ETL Workflow

1. **Extract** â†’ Read raw CSV into Pandas.  
2. **Transform** â†’  
   - Normalize into `customers`, `products`, `sales`.  
   - Assign surrogate keys.  
   - Parse dates + clean columns.  
3. **Load** â†’ Insert into PostgreSQL with SQLAlchemy.  

Data Pipeline:  
- `extract.py` â†’ reads CSV  
- `transform.py` â†’ cleans + normalizes  
- `load.py` â†’ inserts into Postgres  
- `run_etl.py` â†’ orchestrates the steps

